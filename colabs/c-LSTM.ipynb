{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c-LSTM.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kx2sdYAFGW6o8AK-wmn55vIK1i8dimlV","authorship_tag":"ABX9TyMi8At7zv1Y/LH9crBHzvug"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"J6ccmNOo8ari","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1ccf84d7-09e1-45ff-dfc9-bb806b0006a2","executionInfo":{"status":"ok","timestamp":1587979400618,"user_tz":-120,"elapsed":1979,"user":{"displayName":"Erik Tällberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjo4JVT-2XzNFteItAOn33DQIJ0kQvp9zkzzVqmEQ=s64","userId":"04258328018413571488"}}},"source":["cd /content/drive/My Drive/Studier/Master/Master Thesis/Coding/conditional-LSTM-language-model"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Studier/Master/Master Thesis/Coding/conditional-LSTM-language-model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fcqjKxqb824i","colab_type":"text"},"source":["# Data.py"]},{"cell_type":"code","metadata":{"id":"2jILQnJw7nsa","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","import sys\n","import os\n","import random\n","import numpy as np\n","import torch\n","import torch.utils.data as data\n","import glob\n","import logging\n","from collections import defaultdict\n","\n","logging.disable(logging.FATAL)\n","\n","# Set sampling seed\n","torch.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)\n","\n","# Initiate feature vector\n","features = []\n","note_types = ['note', 'rest']\n","tags = ['<WORD>', '<BB>', '<BL>']\n","lengths = [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0, 16.0, 32.0]\n","\n","def get_correct_length(length):\n","    length = int(length)\n","    if length <= 0.25:\n","        return 0.25\n","    elif length <= 0.5:\n","        return 0.5\n","    elif length <= 0.75:\n","        return 0.75\n","    elif length <= 1:\n","        return 1.0\n","    elif length <= 1.5:\n","        return 1.5\n","    elif length <= 2:\n","        return 2.0\n","    elif length <= 3:\n","        return 3.0\n","    elif length <= 4:\n","        return 4.0\n","    elif length <= 6:\n","        return 6.0\n","    elif length <= 8:\n","        return 8.0\n","    elif length <= 16:\n","        return 16.0\n","    elif length <= 32:\n","        return 32.0\n","\n","class SongLyricDataset(data.Dataset):\n","    def __init__(self, data, word_size, window):\n","        \"\"\" Create feature vocab and index dictionaries \"\"\"\n","        # Create feature vocabulary\n","        for i in range(window):\n","            for note_type in note_types:\n","                features.append('note[%s]=%s'%(i, note_type))\n","                features.append('note[%s]=%s'%(-(i+1), note_type))\n","            for length in lengths:\n","                features.append('length[%s]=%s'%(i, length))\n","                features.append('length[%s]=%s'%(-(i+1), length))\n","        for tag in tags:\n","            features.append('prev_tag=%s'%tag)\n","\n","        # Create index dictionaries for features\n","        sorted_features = sorted(features)\n","        self.feature2idx = dict((f, i) for i, f in enumerate(sorted_features))\n","        self.idx2feature = dict((i, f) for i, f in enumerate(sorted_features))\n","        self.feature_size = len(self.feature2idx)\n","\n","        \"\"\" Load data and create word and syllable vocab \"\"\"\n","        # Load data\n","        files = os.listdir(data)\n","\n","        # Initialize word occurance dictionary\n","        word_dict = defaultdict(int)\n","        syll_dict = defaultdict(int)\n","        \n","        # Limit number of songs for testing\n","        # files = files[0:4] \n","\n","        # For each song\n","        for file in files:\n","            notes = np.load(os.path.join(data, file), allow_pickle=True)\n","            old_word_idx = \"<None>\"\n","            # For each word in song lyric increment word occurance dictionary\n","            for note in notes:\n","                # note = [note_number, word_index, note_type, duration, word, syllable, feature_type]\n","                # note[0] = note_number, note[1] = word_index, note[2] = note_type(rest) or MIDI_number, note[3] = duration \n","                # note[4] = word, note[5] = syllable, note[6] = [all syllables], note[7]= feature_type\n","                word_idx = note[1]\n","                if word_idx != old_word_idx:\n","                    word_lower = note[5].lower()\n","                    word_dict[word_lower] += 1\n","                    syll_dict[word_lower] += len(note[6])\n","\n","\n","        # Create index dictionaries for words\n","        self.word2idx = {}\n","        self.word2idx[\"<pad>\"] = 0 # Padding token to fill batches\n","        self.word2idx[\"<unk>\"] = 1 # Unknown token to replace rare words\n","        self.word2idx[\"<BB>|<null>\"] = 2\n","        self.word2idx[\"<BL>|<null>\"] = 3\n","        self.idx2word = {}\n","        self.idx2word[0] = \"<pad>\"\n","        self.idx2word[1] = \"<unk>\"\n","        self.idx2word[2] = \"<BB>|<null>\"\n","        self.idx2word[3] = \"<BL>|<null>\"\n","        \n","        idx = 4\n","        syllables = set()\n","\n","        # Create word index embedding dictionaries\n","        print(\"Number of unique words: %s\" %len(word_dict.items()))\n","        for word, freq in sorted(word_dict.items(), key=lambda x:x[1], reverse=True)[:word_size:]: # Sort word_dict after frequency and limit size to word_size (size of our dictionary)\n","            # Add number of syllables for each word, calculate average number of syllables per word and average\n","            syllables.add(np.round(syll_dict[word]/freq))\n","\n","            # Build word/index dictionaries\n","            self.word2idx[word] = idx\n","            self.idx2word[idx] = word\n","            idx += 1\n","\n","        self.word_size = len(self.word2idx)\n","        self.syllable_size = int(max(syllables) + 10)\n","\n","        # print(\"word size: \", self.word_size)\n","        # print(\"syllable size: \", self.syllable_size)\n","\n","\n","        \"\"\" Create syllable, lyric and melody embeddings \"\"\"\n","        self.idx2lyrics = []\n","        self.idx2syllable = []\n","        self.idx2melody = []\n","\n","        # For each song\n","        for file in files:\n","            notes = np.load(os.path.join(data, file), allow_pickle=True)\n","\n","            # Define starting state\n","            old_word_idx = \"<None>\"\n","            tag_stack = [\"<WORD>\"]\n","            \n","            # Initiate arrays\n","            syllables = []\n","            lyrics = []\n","            melody = []\n","\n","            old_word_idx = \"<None>\"\n","            \n","            \"\"\" For each word in song lyric increment word occurance dictionary \"\"\"\n","            \n","            # NOTE: A feature vectore \"feature[]\" contains the indexes of the features previous tag (BB,BL or WORD) \n","            # Then it also contain the 10 previous note or rest indexes based on position in window as well as the specific rests/notes indexed duration\n","            # Then it also contain the 10 upcoming note or rests indexes and durations in the same manner.\n","            # So to conclude it looks like this: feature = [prev_tag, [previous notes/rests], [upcoming notes/rest]]\n","            # eg.: index of the following [prev_tag = BL, note[-10]=note, note_dur, note[-9]=rest, rest_dur, ...,\n","            #                                note[-1]=note, note_dur, note[0]= note,note_dur, note[1]=rest, rest_dur, note[2] = note, note_dur, note[3]=note, note_dur, ...]\n","            # which in this case would be something like: [280, 240, 108, ...]\n","\n","            for i, note in enumerate(notes):\n","                feauture_type = note[7]\n","\n","                word_idx = note[1]\n","                if word_idx != old_word_idx:\n","                    # This defines and lists the window for previous and upcoming notes\n","                    prev_i = i - window + 1\n","                    if prev_i < 0: \n","                        prev_i = 0\n","                    prev_notes = notes[prev_i:i]\n","\n","                    next_i = i + window\n","                    if next_i > len(notes):\n","                        next_i = len(notes)\n","                    next_notes = notes[i:next_i]\n","\n","                    # If feature type is BB\n","                    if feauture_type == \"<BB>\":\n","                        feature = [] # Initiatie the feature vector which is to contain the \n","\n","                        w_idx = self.word2idx.get(\"<BB>|<null>\") # Get word index of BB feature\n","                        lyrics.append(w_idx) # Append lyric array with feature\n","                        syllables.append(1) # Append syllable array with 1\n","\n","                        prev_tag = self.feature2idx[\"prev_tag=%s\"%tag_stack[-1]]\n","                        feature.append(prev_tag)\n","\n","                        # For previous 8 notes in window\n","                        for j, prev_note in enumerate(prev_notes):\n","                            if prev_note[2] == 'rest':\n","                                note_num = self.feature2idx[\"note[-%s]=rest\"%(len(prev_notes)-j)]\n","                            else:\n","                                note_num = self.feature2idx[\"note[-%s]=note\"%(len(prev_notes)-j)]\n","                            \n","                            note_duration = self.feature2idx[\"length[-%s]=%s\"%((len(prev_notes)-j), get_correct_length(prev_note[3]))]\n","                            \n","                            feature.append(note_num)\n","                            feature.append(note_duration)\n","\n","\n","                        # For upcoming 8 notes in the window\n","                        for j, next_note in enumerate(next_notes):\n","                            if next_note[2] == 'rest':\n","                                note_num = self.feature2idx[\"note[%s]=rest\"%(len(next_note)-j)]\n","                            else:\n","                                note_num = self.feature2idx[\"note[%s]=note\"%(len(next_note)-j)]\n","\n","                            note_duration = self.feature2idx[\"length[%s]=%s\"%(len(next_note)-j, get_correct_length(next_note[3]))]\n","\n","                            feature.append(note_num)\n","                            feature.append(note_duration)\n","\n","                        # Pad feature vector (add elements to fill the array)\n","                        feature = [feature[0]]*(39 - len(feature)) + feature # (adds the first element several times if its shorter than 39)\n","\n","                        # The feature vector is built up as indexes of ['prev_tag', 'note_num', 'note_duration', 'note_num', 'note_duration', ..., 'next_tag', 'note_num', 'note_duration, ...]\n","                        melody.append(feature[::])\n","                        tag_stack.append(\"<BB>\")\n","\n","                    if feauture_type == \"<BL>\":\n","                        feature = [] # Initiatie the feature vector which is to contain the \n","\n","                        w_idx = self.word2idx.get(\"<BL>|<null>\") # Get word index of BB feature\n","                        lyrics.append(w_idx) # Append lyric array with feature\n","                        syllables.append(1) # Append syllable array with 1\n","\n","                        prev_tag = self.feature2idx[\"prev_tag=%s\"%tag_stack[-1]]\n","                        feature.append(prev_tag)\n","\n","                        # For previous 8 notes in window\n","                        for j, prev_note in enumerate(prev_notes):\n","                            if prev_note[2] == 'rest':\n","                                note_num = self.feature2idx[\"note[-%s]=rest\"%(len(prev_notes)-j)]\n","                            else:\n","                                note_num = self.feature2idx[\"note[-%s]=note\"%(len(prev_notes)-j)]\n","                            \n","                            note_duration = self.feature2idx[\"length[-%s]=%s\"%((len(prev_notes)-j), get_correct_length(prev_note[3]))]\n","                            \n","                            feature.append(note_num)\n","                            feature.append(note_duration)\n","\n","\n","                        # For upcoming 8 notes in the window\n","                        for j, next_note in enumerate(next_notes):\n","                            if next_note[2] == 'rest':\n","                                note_num = self.feature2idx[\"note[%s]=rest\"%(len(next_note)-j)]\n","                            else:\n","                                note_num = self.feature2idx[\"note[%s]=note\"%(len(next_note)-j)]\n","\n","                            note_duration = self.feature2idx[\"length[%s]=%s\"%(len(next_note)-j, get_correct_length(next_note[3]))]\n","\n","                            feature.append(note_num)\n","                            feature.append(note_duration)\n","\n","                        # Pad feature vector (add elements to fill the array)\n","                        feature = [feature[0]]*(39 - len(feature)) + feature # (adds the first element several times if its shorter than 39)\n","\n","                        # The feature vector is built up as indexes of ['prev_tag', 'note_num', 'note_duration', 'note_num', 'note_duration', ..., 'next_tag', 'note_num', 'note_duration, ...]\n","                        melody.append(feature[::])\n","                        tag_stack.append(\"<BL>\")                        \n","\n","                    feature = []\n","                    w_idx = self.word2idx.get(note[4], self.word2idx[\"<unk>\"])\n","                    lyrics.append(w_idx) # Append lyric array with feature index\n","                    syllables.append(len(note[6])) # Append sylable array with number of features\n","\n","                    prev_tag = self.feature2idx[\"prev_tag=%s\"%tag_stack[-1]]\n","                    feature.append(prev_tag)\n","\n","                    # For previous 8 notes in window\n","                    for j, prev_note in enumerate(prev_notes):\n","                        if prev_note[2] == 'rest':\n","                            note_num = self.feature2idx[\"note[-%s]=rest\"%(len(prev_notes)-j)]\n","                        else:\n","                            note_num = self.feature2idx[\"note[-%s]=note\"%(len(prev_notes)-j)]\n","                        \n","                        note_duration = self.feature2idx[\"length[-%s]=%s\"%((len(prev_notes)-j), get_correct_length(prev_note[3]))]\n","                        \n","                        feature.append(note_num)\n","                        feature.append(note_duration)\n","\n","                    # For upcoming 8 notes in the window\n","                    for j, next_note in enumerate(next_notes):\n","                        if next_note[2] == 'rest':\n","                            note_num = self.feature2idx[\"note[%s]=rest\"%(len(next_note)-j)]\n","                        else:\n","                            note_num = self.feature2idx[\"note[%s]=note\"%(len(next_note)-j)]\n","\n","                        note_duration = self.feature2idx[\"length[%s]=%s\"%(len(next_note)-j, get_correct_length(next_note[3]))]\n","\n","                        feature.append(note_num)\n","                        feature.append(note_duration)\n","\n","                    # Pad feature vector (add elements to fill the array)\n","                    feature = [feature[0]]*(39 - len(feature)) + feature # (adds the first element several times if its shorter than 39)\n","                    melody.append(feature[::])\n","                    tag_stack.append(\"<WORD>\")\n","\n","            old_word_idx = word_idx\n","            \n","            # Append syllable, lyric and melody object array with arrays\n","            self.idx2syllable.append(syllables[::]) \n","            # print(\"idx2sylldable: \",self.idx2syllable)\n","            self.idx2lyrics.append(lyrics[::])\n","            # print(\"idx2lyrics: \", self.idx2lyrics)  \n","            self.idx2melody.append(melody[::])\n","            # print(\"idx2melody: \", self.idx2melody)\n","\n","    def __len__(self):\n","        return len(self.idx2lyrics)\n","\n","    def __getitem__(self, idx):\n","        syllables = torch.Tensor(self.idx2syllable[idx])\n","        lyrics = torch.Tensor(self.idx2lyrics[idx])\n","        melody = self.idx2melody[idx]\n","\n","        return syllables, lyrics, melody, self.feature_size\n","\n","\n","def collate_fn(data):\n","    data.sort(key=lambda x: len(x[1]), reverse=True)\n","    # print(\"len(data) = %s\"%len(data))\n","    _syllables, _lyrics, _melody, feature_size = zip(*data)\n","\n","    # print(\"len(_melody) = %s\"%len(_melody))\n","\n","    lengths = [len(_lyric) for _lyric in _lyrics] # Creates an array of the lengths of each songs lyrics\n","    max_length = lengths[0]\n","    \n","    lyrics = torch.zeros(len(_lyrics), max_length).long() # Initialise tensors\n","    syllables = torch.zeros(len(_syllables), max_length).long() # Initialise tensors\n","    melody = torch.zeros(len(_melody), max_length, feature_size[0]).long() # Initialise tensors\n","\n","    for i, _lyric in enumerate(_lyrics):\n","        end = lengths[i]\n","        lyrics[i, :end] = _lyric[:end] # Create one long tensor for all songs\n","        syllables[i, :end] = _syllables[i][:end] # Create one long tensor for all songs\n","        # print(\"_MELODY[i]: \", _melody[i])\n","        # print(\"len(_MELODY[i]: \", len(_melody[i]))\n","        # print(\"Tensor size: \", torch.Tensor(_melody[i]).long().size())\n","        melody[i, :end].scatter_(1, torch.Tensor(_melody[i]).long(), 1) \n","\n","    lengths = torch.Tensor(lengths).long()\n","\n","    return syllables, lyrics, melody, lengths\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fLRnKjG68Cfy","colab_type":"text"},"source":["# Model.py"]},{"cell_type":"code","metadata":{"id":"AV9zCYS18A7Q","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","import torch\n","from torch import nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.nn.functional as F\n","\n","class CLMM(nn.Module):\n","    def __init__(self, word_dim, melody_dim, syllable_size, word_size, feature_size):\n","        super(CLMM, self).__init__()\n","        self.hidden_dim = word_dim + melody_dim\n","\n","        \"\"\" Word embedding \"\"\"\n","        self.embedding = nn.Embedding(word_size, word_dim)\n","\n","        \"\"\" Melody vector \"\"\"\n","        self.fc_melody = nn.Linear(feature_size, melody_dim) # Fully connected layer\n","\n","        \"\"\" LSTM \"\"\"\n","        self.rnn = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=1, bias=True, batch_first=True, bidirectional=False)\n","\n","        \"\"\" Output \"\"\"\n","        self.fc_lyrics_out = nn.Linear((self.hidden_dim), word_size) # Fully connected layer\n","        self.fc_syllables_out = nn.Linear(self.hidden_dim, int(syllable_size)) # Fully connected layer\n","        \n","        \"\"\" Util \"\"\"\n","        self.relu = nn.ReLU(True)\n","        self.bn_lyrics = nn.BatchNorm1d(word_size)\n","        self.bn_syllables = nn.BatchNorm1d(syllable_size)\n","\n","    def forward(self, lyrics, melody, lengths):\n","        lengths = lengths - 1\n","        local_batch_size = lyrics.shape[0]\n","\n","        \"\"\" Word embedding \"\"\"\n","        word_emb = self.embedding(lyrics)\n","\n","        \"\"\" Melody vector \"\"\"\n","        melody_vec = self.relu(self.fc_melody(melody))\n","\n","        \"\"\" Input vector \"\"\"\n","        input_vec = torch.cat((word_emb, melody_vec), dim=2)\n","        input_vec = pack_padded_sequence(input_vec, lengths, batch_first=True)\n","\n","        \"\"\" RNN \"\"\"\n","        output, hidden = self.rnn(input_vec)\n","\n","        \"\"\" Output \"\"\"\n","        lyrics_output = self.fc_lyrics_out(output[0])\n","        syllable_output = self.fc_syllables_out(output[0])\n","\n","        if local_batch_size > 1:\n","            lyrics_output = self.bn_lyrics(lyrics_output) # Batch normalization\n","            syllable_output = self.bn_syllables(syllable_output)\n","\n","        return syllable_output, lyrics_output, hidden\n","\n","    def init_hidden(self, bsz):\n","        weight = next(self.parameters())\n","        return (weight.new_zeros(1, bsz, self.hidden_dim), weight.new_zeros(1, bsz, self.hidden_dim))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7GwMpM_8HCi","colab_type":"text"},"source":["# Utils.py"]},{"cell_type":"code","metadata":{"id":"_jDDQJq-8KTi","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","import json\n","import os\n","import sys\n","import numpy as np\n","import torch\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","    \n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val*n\n","        self.count += n\n","        self.avg = self.sum/self.count\n","\n","\n","class LogPrint:\n","    def __init__(self, file_path, err):\n","        self.file = open(file_path, \"w\", buffering=1)\n","        self.err = err\n","\n","    def lprint(self, text, ret=False, ret2=False):\n","        if self.err:\n","            if ret == True:\n","                if ret2 == True:\n","                    sys.stderr.write(\"\\n\" + text + \"\\n\")\n","                else:\n","                    sys.stderr.write(\"\\r\" + text + \"\\n\")\n","            else:\n","                sys.stderr.write(\"\\r\" + text)\n","        self.file.write(text + \"\\n\")\n","\n","\n","def load_settings(settings):\n","    \"\"\"\n","    Loading settings from the given json settings file. Overwrites command line input.\n","    \"\"\"\n","\n","    # Define settings path\n","    settings_path = './settings/' + settings['settings_file']\n","    print(\"Loading settings from: %s\"%settings_path)\n","\n","    settings_loaded = json.load(open(settings_path, 'r'))\n","\n","    # Check for missing settings in file\n","    for key in settings.keys():\n","        if not key in settings_loaded:\n","            print(key, \" not found in loaded settings\")\n","    \n","    settings.update(settings_loaded)\n","    return settings\n","\n","# Function from PyTorch NLP official example\n","def repackage_hidden(h):\n","    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n","\n","    if isinstance(h, torch.Tensor):\n","        return h.detach()\n","    else:\n","        return tuple(repackage_hidden(v) for v in h)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ipqoogJB8Pgi","colab_type":"text"},"source":["# Train.py\n"]},{"cell_type":"code","metadata":{"id":"6Au467828OeX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":220},"outputId":"a1747ba5-b8a8-464a-d770-213719c62503","executionInfo":{"status":"error","timestamp":1587979512965,"user_tz":-120,"elapsed":4464,"user":{"displayName":"Erik Tällberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjo4JVT-2XzNFteItAOn33DQIJ0kQvp9zkzzVqmEQ=s64","userId":"04258328018413571488"}}},"source":["# -*- coding: utf-8 -*-\n","import os\n","import sys\n","import argparse\n","import json\n","import random\n","import  time\n","import numpy as np\n","import utils\n","import matplotlib.pyplot as plt\n","from data import SongLyricDataset, collate_fn\n","from model import CLMM\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from collections import defaultdict\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(\"Device type: %s\"%device)\n","\n","def main():\n","    \"\"\" Set seeds \"\"\"\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","    \"\"\" Load data \"\"\"\n","    data_set = SongLyricDataset(data, word_size, window)\n","    data_word_size = data_set.word_size\n","    data_feature_size = data_set.feature_size\n","    data_syllable_size = data_set.syllable_size\n","\n","    # Print data stats\n","    lp.lprint(\"------ Data Stats -----\", True)\n","    lp.lprint(\"{:>12}:  {}\".format(\"Number of songs\", len(data_set)), True)\n","    lp.lprint(\"{:>12}:  {}\".format(\"vocab size\", data_word_size), True)\n","    lp.lprint(\"{:>12}:  {}\".format(\"feature size\", data_feature_size), True)\n","    lp.lprint(\"{:>12}:  {}\".format(\"syllable size\", data_syllable_size), True)\n","\n","    \"\"\" Save vocab arrays and models to checkpoint \"\"\"\n","    with open(checkpoint + '.feature.json', 'w') as f:\n","        f.write(json.dumps(data_set.idx2feature))\n","\n","    with open(checkpoint + '.vocab.json', 'w') as f:\n","        f.write(json.dumps(data_set.idx2word))\n","\n","    with open(checkpoint + '.param.json', 'w') as f:\n","        f.write(json.dumps({\"feature_idx_path\": checkpoint+'.feature.json',\n","                            \"vocab_idx_path\": checkpoint+'.vocab.json',\n","                            \"word_dim\": word_dim,\n","                            \"syllable_size\": data_syllable_size,\n","                            \"melody_dim\": melody_dim,\n","                            \"feature_size\": data_feature_size,\n","                            \"window\": window,\n","                            \"args_word_size\": word_size}))\n","    \n","\n","    \"\"\" Split data into training and validation data \"\"\"\n","    n_samples = len(data_set)\n","    train_size = int(n_samples*train_rate)\n","    validation_size = int((n_samples - train_size)/2)\n","    test_size = validation_size\n","    \n","    train_data_set, val_data_set, test_data_set = torch.utils.data.random_split(data_set, [train_size, validation_size, test_size])\n","\n","    print(\"Training set: \", len(train_data_set), \" songs, Validation set: \", len(val_data_set), \" songs, \"\n","          \"Test set: \", len(test_data_set), \" songs.\")\n","\n","    \"\"\" Create PyTorch dataloaders \"\"\"\n","    train_data_loader = torch.utils.data.DataLoader(dataset=train_data_set,\n","                                                    batch_size=batch_size,\n","                                                    shuffle=True,\n","                                                    num_workers=num_workers,\n","                                                    collate_fn=collate_fn)\n","\n","    val_data_loader = torch.utils.data.DataLoader(dataset=val_data_set,\n","                                                  batch_size=batch_size,\n","                                                  shuffle=True,\n","                                                  num_workers=num_workers, \n","                                                  collate_fn=collate_fn)\n","\n","    # test_data_loader = torch.utils.data.DataLoader(dataset=test_data_set,\n","    #                                               batch_size=batch_size,\n","    #                                               shuffle=True,\n","    #                                               num_workers=num_workers, \n","    #                                               collate_fn=collate_fn)\n","\n","    \"\"\" Load CLLM model \"\"\"\n","    model = CLMM(word_dim=word_dim, melody_dim=melody_dim, syllable_size=data_syllable_size, word_size=data_word_size, feature_size=data_feature_size).to(device)\n","\n","    \"\"\" Build Optimizers \"\"\"\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # lr = 0.001\n","    loss_criterion = nn.CrossEntropyLoss() # Combines LogSoftmax() and NLLLoss() (Negative log likelihood loss)\n","\n","    \"\"\" Define traingin function \"\"\"\n","    def train(epoch, data_set, data_loader):\n","        model.train() # Activate train mode\n","\n","        # Log time\n","        batch_time = utils.AverageMeter()\n","        data_time = utils.AverageMeter()\n","        sum_losses_syll = utils.AverageMeter()\n","        sum_losses_lyric = utils.AverageMeter()\n","        start_time = time.time()\n","\n","        \"\"\" Batches \"\"\"\n","        hidden = model.init_hidden(batch_size) # Creates a list of 3D layers with 1 x batch_size x hidden_dim\n","\n","        for i, (syllable, lyric, melody, lengths) in enumerate(data_loader):\n","            # Take time\n","            elapsed = time.time()\n","            data_time.update((elapsed - start_time)*1000)\n","\n","            \"\"\" Move dataloaders to GPU \"\"\"\n","            syllable = syllable.to(device)\n","            lyric = lyric.to(device)\n","            melody = melody.to(device).float()\n","            lengths = lengths.to(device)\n","\n","            \"\"\" Remove first melody feature \"\"\"\n","            melody = melody[:, 1:] # We dont really want to do this?\n","\n","            \"\"\" Reset gradient to zero \"\"\"\n","            optimizer.zero_grad()\n","\n","            \"\"\" Detach hidden layers \"\"\"\n","            hidden = utils.repackage_hidden(hidden) # Function from PyTorch NLP official example\n","\n","            \"\"\" Feedforward \"\"\"\n","            # Feedforward\n","            syllable_output, lyrics_output, hidden = model(lyric[:, :-1], melody, lengths)\n","            \n","            # Define packed padded targets\n","            target_syllable = pack_padded_sequence(syllable[:, 1:], lengths-1, batch_first=True)[0]\n","            target_lyrics = pack_padded_sequence(lyric[:, 1:], lengths-1, batch_first=True)[0]\n","            \n","            # Calculate and update Cross-Entropy loss\n","            loss_syllable = loss_criterion(syllable_output, target_syllable)\n","            sum_losses_syll.update(loss_syllable)\n","\n","            loss_lyrics = loss_criterion(lyrics_output, target_lyrics)\n","            sum_losses_lyric.update(loss_lyrics)\n","\n","            \"\"\" Backpropagation \"\"\"\n","            loss = loss_syllable + loss_lyrics\n","            loss.backward()\n","            optimizer.step()\n","\n","            \"\"\" Time \"\"\"\n","            elapsed = time.time()\n","            batch_time.update((elapsed - start_time))\n","\n","            \"\"\" Print progress \"\"\"\n","            if i % log_interval == 0:\n","                lp.lprint('| Training Epoch: {:3d}/{:3d}  {:6d}/{:6d} '\n","                          '| lr:{:6.5f} '\n","                          '| {batch_time.avg:7.2f} s/batch '\n","                          '| {data_time.avg:5.2f} ms/data_load '\n","                          '| Loss(Syllable) {loss_s.avg:5.5f} '\n","                          '| Loss(Lyrics) {loss_l.avg:5.5f} |'\n","                          .format(epoch+1, num_epochs, i, len(data_loader), lr, \n","                                  batch_time=batch_time,\n","                                  data_time=data_time, \n","                                  loss_s=sum_losses_syll, \n","                                  loss_l=sum_losses_lyric))\n","        return sum_losses_lyric.avg, sum_losses_syll.avg\n","\n","\n","    def validation(epoch, data_set, data_loader):\n","        model.eval()\n","\n","        # Log time\n","        batch_time = utils.AverageMeter()\n","        data_time = utils.AverageMeter()\n","        sum_losses_syll = utils.AverageMeter()\n","        sum_losses_lyric = utils.AverageMeter()\n","        start_time = time.time()\n","\n","        \"\"\" Batches \"\"\"\n","        hidden = model.init_hidden(batch_size) # Creates a list of 3D layers with 1 x batch_size x hidden_dim\n","\n","        for i, (syllable, lyric, melody, lengths) in enumerate(data_loader):\n","            # Take time\n","            elapsed = time.time()\n","            data_time.update((elapsed - start_time)*1000)\n","\n","            \"\"\" Move dataloaders to GPU \"\"\"\n","            syllable = syllable.to(device)\n","            lyric = lyric.to(device)\n","            melody = melody.to(device).float()\n","            lengths = lengths.to(device)\n","\n","            \"\"\" Remove first melody feature \"\"\"\n","            melody = melody[:, 1:] # We dont really want to do this?\n","\n","            \"\"\" Reset gradient to zero \"\"\"\n","            optimizer.zero_grad()\n","\n","            \"\"\" Detach hidden layers \"\"\"\n","            hidden = utils.repackage_hidden(hidden) # Function from PyTorch NLP official example\n","\n","            \"\"\" Feedforward \"\"\"\n","            # Feedforward\n","            syllable_output, lyrics_output, hidden = model(lyric[:, :-1], melody, lengths)\n","            \n","            # Define packed padded targets\n","            target_syllable = pack_padded_sequence(syllable[:, 1:], lengths-1, batch_first=True)[0]\n","            target_lyrics = pack_padded_sequence(lyric[:, 1:], lengths-1, batch_first=True)[0]\n","            \n","            # Calculate and update Cross-Entropy loss\n","            loss_syllable = loss_criterion(syllable_output, target_syllable)\n","            sum_losses_syll.update(loss_syllable)\n","\n","            loss_lyrics = loss_criterion(lyrics_output, target_lyrics)\n","            sum_losses_lyric.update(loss_lyrics)\n","\n","            \"\"\" Time \"\"\"\n","            elapsed = time.time()\n","            batch_time.update((elapsed - start_time))\n","\n","            \"\"\" Print progress \"\"\"\n","            if i % log_interval == 0:\n","                lp.lprint('| Validation Epoch: {:3d}/{:3d}  {:6d}/{:6d} '\n","                          '| lr:{:6.5f} '\n","                          '| {batch_time.avg:7.2f} s/batch '\n","                          '| {data_time.avg:5.2f} ms/data_load '\n","                          '| Loss(Syllable) {loss_s.avg:5.5f} '\n","                          '| Loss(Lyrics) {loss_l.avg:5.5f} |'\n","                          .format(epoch+1, num_epochs, i, len(data_loader), lr, \n","                                  batch_time=batch_time,\n","                                  data_time=data_time, \n","                                  loss_s=sum_losses_syll, \n","                                  loss_l=sum_losses_lyric))\n","        return sum_losses_lyric.avg, sum_losses_syll.avg\n","\n","\n","    def test(data_set, data_loader):\n","        print(\"test\")\n","\n","    def save_model(epoch):\n","        model.eval()\n","        with open(checkpoint+\"_%02d.pt\"%(epoch+1), 'wb') as f:\n","            torch.save(model.state_dict(), f)\n","\n","    \"\"\" Run Epochs \"\"\"\n","    lp.lprint(\"------ Training -----\", True)\n","    first_start_time = time.time()\n","    train_lyric_loss_vec = []\n","    train_syll_loss_vec = []\n","    val_lyric_loss_vec = []\n","    val_syll_loss_vec = []\n","    for epoch in range(num_epochs):\n","        # Training \n","        train_lyric_loss, train_syll_loss = train(epoch, train_data_set, train_data_loader)\n","        train_lyric_loss_vec.append(train_lyric_loss)\n","        train_syll_loss_vec.append(train_syll_loss)\n","        lp.lprint(\"\", True)\n","\n","        # Validation\n","        with torch.no_grad():\n","            val_lyric_loss, val_syll_loss = validation(epoch, val_data_set, val_data_loader)\n","            val_lyric_loss_vec.append(val_lyric_loss)\n","            val_syll_loss_vec.append(val_syll_loss)\n","            lp.lprint(\"\", True)\n","\n","            # Save checkpoint\n","            save_model(epoch)\n","\n","        # Plot training loss\n","        plt.figure('train', (12, 6))\n","        plt.subplot(1, 2, 1)\n","        plt.title('Training lyric loss')\n","        plt.ylabel('Train lyric loss')\n","        plt.xlabel('Epoch')\n","        plt.plot(train_lyric_loss_vec)\n","        plt.subplot(1, 2, 2)\n","        plt.title('Training syllable loss')\n","        plt.ylabel('Train syllable loss')\n","        plt.xlabel('Epoch')\n","        plt.plot(train_syll_loss_vec)\n","        plt.show()\n","\n","        # Plot validation loss\n","        plt.figure('validation', (12, 6))\n","        plt.subplot(1, 2, 1)\n","        plt.title('Validation lyric loss')\n","        plt.ylabel('Validation lyric loss')\n","        plt.xlabel('Epoch')\n","        plt.plot(val_lyric_loss_vec)\n","        plt.subplot(1, 2, 2)\n","        plt.title('Validation syllable loss')\n","        plt.ylabel('Validation syllable loss')\n","        plt.xlabel('Epoch')\n","        plt.plot(val_syll_loss_vec)\n","        plt.show()\n","\n","\n","        lp.lprint(\"-----------\", True)\n","    elapsed = (time.time() - first_start_time)/60\n","    lp.lprint('Total elapsed time: {elapsed:7.2f} minutes'.format(elapsed=elapsed))\n","    \n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description=\"Train a conditional-LSTM language model to generate lyrics given melody\")\n","    parser.add_argument('--settings_file', help='json file of settings, overrides everything else', type=str, default='settings.txt')\n","    parser.add_argument('-verbose', '--verbose', dest=\"verbose\", default=1, type=int, help=\"verbose: 0 or 1\")\n","\n","    args = parser.parse_args()\n","    settings = vars(args)\n","    settings = utils.load_settings(settings)\n","    \n","    print(settings[\"checkpoint\"])\n","\n","    if args.verbose == 1:\n","        lp = utils.LogPrint(settings['checkpoint'] + '.log', True)\n","    else:\n","        lp = utils.LogPrint(settings['checkpoint'] + '.log', False)\n","\n","    # Print settings\n","    lp.lprint(\"------ Parameters -----\", True)\n","    for (k, v) in settings.items():\n","        lp.lprint(\"{:>16}:  {}\".format(k, v), True)\n","    \n","    # Log settings\n","    with open(settings['checkpoint']+'args.json', 'w') as f:\n","        f.write(json.dumps(settings))\n","    \n","    # Update local variables\n","    locals().update(settings)\n","\n","    # Redefine variables to avoid annoying text editor errors\n","    lr = lr\n","    batch_size = batch_size\n","    checkpoint = checkpoint\n","    word_size = word_size\n","    word_dim = word_dim\n","    melody_dim = melody_dim\n","    num_workers = num_workers\n","    seed = seed\n","    window = window\n","    train_rate = train_rate\n","    data = data\n","    num_epochs = num_epochs\n","    log_interval = log_interval\n","\n","\n","    main()\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Device type: cuda:0\n"],"name":"stdout"},{"output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [--settings_file SETTINGS_FILE]\n","                             [-verbose VERBOSE]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-a37de38c-60ce-4267-a0a2-2f3159acbd73.json\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Tq7YTcfl9Kxk","colab_type":"text"},"source":["# Bottom"]}]}